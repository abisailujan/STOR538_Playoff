---
title: "Playoff_good"
author: "Alexandra Myers"
date: "2025-02-28"
output: html_document
---

Package Bank
```{r}
library(readr)
library(tidyverse)
library(dplyr)
library(stringr)
library(xgboost)
library(caret)
library(Matrix)
library(zoo)
```

# Clean + Merge
## Read
```{r message=FALSE}
# Playoff Datasets------
PO_BoxScores <- read_csv("~/Desktop/STOR 538/Playoff/Starting Data/play_off_box_scores_2010_2024.csv")
PO_Totals <- read_csv("~/Desktop/STOR 538/Playoff/Starting Data/play_off_totals_2010_2024.csv")

# Regular Season Datasets------
RS_BoxScores_P1 <- read_csv("~/Desktop/STOR 538/Playoff/Starting Data/regular_season_box_scores_2010_2024_part_1.csv")
RS_BoxScores_P2 <- read_csv("~/Desktop/STOR 538/Playoff/Starting Data/regular_season_box_scores_2010_2024_part_2.csv")
RS_BoxScores_P3 <- read_csv("~/Desktop/STOR 538/Playoff/Starting Data/regular_season_box_scores_2010_2024_part_3.csv")
RS_Totals <- read_csv("~/Desktop/STOR 538/Playoff/Starting Data/regular_season_totals_2010_2024.csv")
```

## Examine
```{r eval=FALSE, include=FALSE}
# A) Missing Values
colSums(is.na(PO_Totals)) # available flag 336 missing values
sum(PO_Totals$AVAILABLE_FLAG == 0, na.rm = TRUE) # available flag has 30 zeros
colSums(is.na(RS_Totals)) # avialable flag has 4454 missing values
sum(RS_Totals$AVAILABLE_FLAG == 0, na.rm = TRUE) # 128 zeros
# ------------------------------------------------
# B) Duplicates
duplicated(PO_BoxScores)
```

## Clean
```{r}
# A) Remove rows with 0 or NA in AVAILABLE_FLAG bc "data unavailable" (README)
PO_Totals <- PO_Totals %>% 
  filter(!is.na(AVAILABLE_FLAG) & AVAILABLE_FLAG != 0)

RS_Totals <- RS_Totals %>% 
  filter(!is.na(AVAILABLE_FLAG) & AVAILABLE_FLAG != 0)
# ------------------------------------------------
# B) Only on of the data sets had duplicates
PO_BoxScores <- distinct(PO_BoxScores)
```

## Merge
```{r}
# The P1, P2, P3 have the same columns
    # so horizontally append w bind_rows
RS_BoxScores <- bind_rows(RS_BoxScores_P1, RS_BoxScores_P2, RS_BoxScores_P3)

# ------------------------------------------------
# Merge based on game and team ID
    # Match datatypes before merge; otherwise causing error
RS_BoxScores <- RS_BoxScores %>%
  mutate(gameId = as.numeric(gameId), teamId = as.numeric(teamId))
PO_BoxScores <- PO_BoxScores %>%
  mutate(gameId = as.numeric(gameId), teamId = as.numeric(teamId))
RS_Totals <- RS_Totals %>%
  mutate(GAME_ID = as.numeric(GAME_ID), TEAM_ID = as.numeric(TEAM_ID))
PO_Totals <- PO_Totals %>%
  mutate(GAME_ID = as.numeric(GAME_ID), TEAM_ID = as.numeric(TEAM_ID))

    # Merge by only matching GameIds and TeamIds; a few rows get eliminated here
RS <- inner_join(
  RS_BoxScores, RS_Totals, 
  by = c("gameId" = "GAME_ID", "teamId" = "TEAM_ID"))
PO <- inner_join(
  PO_BoxScores, PO_Totals, 
  by = c("gameId" = "GAME_ID", "teamId" = "TEAM_ID"))

# ------------------------------------------------
# Final merge
NBA_Data <- bind_rows(RS, PO) %>%
    # Remove some columns
    select(-(teamSlug), -(comment), -(jerseyNum),
             -(SEASON_YEAR), -(TEAM_ABBREVIATION),
             -(TEAM_NAME), -(MATCHUP)) %>%

    # Make an opponent column
  mutate(opponentTricode = str_sub(matchup, -3)) %>%
  select(teamTricode, opponentTricode, everything())  %>%
  
    # Arrange as how Mario asked
  arrange(teamId, game_date, opponentTricode) 
```



## > Effective Field Goal %
Formula:
http://www.crackedsidewalks.com/2022/07/who-will-score-part-v-calculating-efg.html

- **FGM**: Field goals made.
- **FGA**: Field goals attempted.
- **FG3M**: Three-point field goals made.
```{r}
NBA_Data2 <- NBA_Data2 %>%
  mutate(eFG_Percentage = (FGM + 0.5*FG3M) / FGA)
```

# Break Into H vs A Dataset
vs indicates home team
@ indicates away team
```{r}
# Create Home and Away datasets
NBA_Home <- NBA_Data %>% filter(str_detect(matchup, "vs\\.")) %>%
  rename_at(vars(-c(gameId, game_date)), ~paste0("H_", .))  
NBA_Away <- NBA_Data %>% filter(str_detect(matchup, "@")) %>%
  rename_at(vars(-c(gameId, game_date)), ~paste0("A_", .))  


write_csv(NBA_Home, "NBA_Home.csv")
write_csv(NBA_Away, "NBA_Away.csv")

NBA_Data2 <- merge(NBA_Home, NBA_Away)
```

# Outside Data
# Read
nbastatR Dataset
Each row is a unique gameID
```{r message=FALSE}
nbastatR <- read_csv("~/Desktop/STOR 538/Playoff/Data2025.csv")
```


```{r}
# Pace: An estimate of how many possesions a team gets during a full 48 minute game. The higher the pace the faster the team's playstyle leading to more points 
RS_Totals$PACE = (RS_Totals$FGA + 0.44 * RS_Totals$FTA - RS_Totals$OREB + RS_Totals$TOV) / (RS_Totals$MIN / 48)

reg_totals_selected <- RS_Totals %>% 
  select(SEASON_YEAR,
         TEAM_ABBREVIATION,
         TEAM_NAME, 
         GAME_DATE, 
         GAME_ID,
         MATCHUP,
         FGM,
         FGA,
         FG_PCT,
         FG3M,
         FG3A,
         FG3_PCT,
         FTM,
         FTA,
         FT_PCT,
         OREB,
         DREB,
         REB,
         AST,
         TOV,
         STL,
         BLK,
         BLKA,
         PF,
         PFD,
         PTS,
         PLUS_MINUS,
         PACE
         )

opposing_stats <- c("FGM", "FGA", "FG_PCT", "FG3M", "FG3A", "FG3_PCT",
                    "FTM", "FTA", "FT_PCT", "OREB", "DREB", "REB",
                    "AST", "TOV", "STL", "BLK", "BLKA", "PF",
                    "PFD", "PTS", "PLUS_MINUS", "PACE")

add_opponent_stats <- function(df) {
  df_opp <- df %>%
    select(GAME_ID, GAME_DATE, TEAM_ABBREVIATION, all_of(opposing_stats)) %>%
    rename_with(~ paste0("o", .), all_of(opposing_stats)) %>%
    rename(TEAM_ABBREVIATION_opp = TEAM_ABBREVIATION)
  
  df %>%
    left_join(df_opp, by = c("GAME_ID", "GAME_DATE")) %>%
    filter(TEAM_ABBREVIATION != TEAM_ABBREVIATION_opp | is.na(TEAM_ABBREVIATION_opp))
}


# Dataset with opposing team game by game stats

reg_totals_with_oppo <- add_opponent_stats(reg_totals_selected)

# To check opposing data calculations are correct I'm grouping and comparing to official records

reg_totals_with_oppo_1516 <- reg_totals_with_oppo %>% filter(SEASON_YEAR == "2015-16")

reg_totals_with_oppo_grouped_1516 <- reg_totals_with_oppo_1516 %>% 
  group_by(TEAM_NAME) %>% 
  summarise(
    avgPTS = round(mean(PTS, na.rm = TRUE), 1),
    avgREB = round(mean(REB, na.rm = TRUE), 1),
    AVGAST = round(mean(AST, na.rm = TRUE), 1),
    avgPACE = round(mean(PACE, na.rm = TRUE), 1),
    avgoPTS = round(mean(oPTS, na.rm = TRUE), 1),
    avgoREB = round(mean(oREB, na.rm = TRUE), 1),
    AVGoAST = round(mean(oAST, na.rm = TRUE), 1),
    avgoPACE = round(mean(oPACE, na.rm = TRUE), 1),
    
  )

rolling_df2 <- RS_Totals %>%
  mutate(eFG_Percentage = (FGM + 0.5*FG3M) / FGA)

NBA_Home <- RS_Totals %>% filter(str_detect(MATCHUP, "vs\\.")) %>%
  rename_at(vars(-c(GAME_ID, GAME_DATE)), ~paste0("H_", .))  
NBA_Away <- RS_Totals %>% filter(str_detect(MATCHUP, "@")) %>%
  rename_at(vars(-c(GAME_ID, GAME_DATE)), ~paste0("A_", .))  

rolling_df2 <- merge(NBA_Home, NBA_Away)
```

# New variables
```{r}
NBA_Data2 <- NBA_Data2 %>%
  mutate(lag_H_pts = rollapply(NBA_Data2$H_PTS, width = 5, FUN = mean, fill = NA, align = "right"),
         lag_A_pts = rollapply(NBA_Data2$A_PTS, width = 5, FUN = mean, fill = NA, align = "right"),
         lag_H_FGA = rollapply(NBA_Data2$H_FGA, width = 5, FUN = mean, fill = NA, align = "right"), 
         lag_A_FGA = rollapply(NBA_Data2$A_FGA, width = 5, FUN = mean, fill = NA, align = "right"), 
         lag_H_FGM = rollapply(NBA_Data2$H_FGM, width = 5, FUN = mean, fill = NA, align = "right"),
         lag_A_FGM = rollapply(NBA_Data2$A_FGM, width = 5, FUN = mean, fill = NA, align = "right"),
         spread = (H_PTS - A_PTS))
```


# Model - predicting spread of each game
# find out how to get the matchup back in

```{r}
# Modeling Using rolling_df2 (Rolling Averages)

target_col_roll <- "point_spread"  

# Select only rolling averaged features (all columns starting with "roll_")
numeric_features_roll <- rolling_df2 %>%
  select(starts_with("roll_")) %>%
  as.matrix()

# Target variable remains the original TOTAL column
y_roll <- rolling_df2[[target_col_roll]]

if (is.factor(y_roll)) {
  y_roll <- as.numeric(y_roll) - 1  
}

# Standardize the rolling features
preproc_roll <- preProcess(numeric_features_roll, method = c("center", "scale"))
numeric_features_roll <- predict(preproc_roll, numeric_features_roll)

set.seed(123)
folds_roll <- createFolds(y_roll, k = 10, list = TRUE, returnTrain = TRUE)

# Create a new DMatrix for rolling data
dtrain_roll <- xgb.DMatrix(data = numeric_features_roll, label = y_roll)


predict <- rolling_df2 %>%
  mutate(point_spread = H_PTS - A_PTS) %>%
  select(-c(GAME_DATE, H_SEASON_YEAR, A_SEASON_YEAR, H_TEAM_ABBREVIATION, A_TEAM_ABBREVIATION, H_MATCHUP, A_MATCHUP, -matches("RANK"))) %>%
  mutate(H_WL = ifelse(H_WL == "W", 1, 0),
         A_WL = ifelse(A_WL == "W", 1, 0))

predict$H_TEAM_NAME <- as.numeric(as.factor(predict$H_TEAM_NAME))
predict$A_TEAM_NAME <- as.numeric(as.factor(predict$A_TEAM_NAME))

set.seed(123)  # For reproducibility
train_index <- createDataPartition(predict$point_spread, p = 0.8, list = FALSE)
train_data <- predict[train_index, ]
test_data <- predict[-train_index, ]

train_label <- train_data$point_spread
train_features <- train_data %>% select(-point_spread, -H_PTS, -A_PTS) %>% as.matrix() # variables used

test_label <- test_data$point_spread
test_features <- test_data %>% select(-point_spread, -H_PTS, -A_PTS) %>% as.matrix()

dtrain <- xgb.DMatrix(data = train_features, label = train_label)
dtest <- xgb.DMatrix(data = test_features, label = test_label)

params <- list(
  objective = "reg:squarederror",  # Regression task
  eval_metric = "mae",  # Mean Absolute Error (MAE)
  max_depth = 6,  
  eta = 0.05,   # slow training, better accuracy and generalization, 0.3< = risk of overfitting - scales the contribution of each tree, preventing the model from adjusting to aggressively
  subsample = 0.8, # reduces variance, prevents over fitting, similar to bagging in RF - because < 0.1, uses only a fraction of the data, adding randomness. commonly used to reduce overfitting, keeping strong learning power
  colsample_bytree = 0.8  # commonly used, good balance of regularization and model performance, prevents overfitting by reducing feature dependence and increasing model diversity. 
)

xgb_model <- xgb.train(params = params, 
                       data = dtrain, 
                       nrounds = 300,  # builds trees sequentially, each new tree corrects the errors of previous trees
                       watchlist = list(train = dtrain, test = dtest),
                       verbose = 1)
cv_results <- xgb.cv(params, dtrain, nrounds = 300, nfold = 5, 
                     early_stopping_rounds = 10)

predictions <- predict(xgb_model, dtest)
mae <- mean(abs(predictions - test_label))
print(paste("MAE:", round(mae, 2)))

table <- data.frame(
  Actual= test_data$point_spread,
  Predicted = predictions,
  MAE = abs(test_label-predictions)
)
view(table)

test_data$predictions <- predictions 
test_data$MAE <- abs(test_data$point_spread-test_data$predictions)

avg_mae <- predict %>%
  summarize(mean = mean(abs(point_spread)))
avg_mae

importance_roll <- xgb.importance(feature_names = colnames(train_features), model = xgb_model)
importance <- xgb.plot.importance(importance_roll)
xgb.plot.importance(importance_roll)
import <- xgb.plot.importance(importance_roll)
print(import)

# 0.02
```


```{r}
train_index1 <- createDataPartition(finalS$point_spread, p = 0.8, list = FALSE)
train_data1 <- finalS[train_index, ]
dtrain <- xgb.DMatrix(data = as.matrix(finalS), label = )
params <- list(
  objective = "reg:absoluteerror",  # Use appropriate objective for your task
  booster = "gbtree",
  eta = 0.1, 
  max_depth = 6,
  subsample = 0.8,
  colsample_bytree = 0.8,
  eval_metric = "mae"  # Change metric if necessary
)

# Perform 10-fold Cross-Validation
cv_results <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 100,  # Adjust based on your model
  nfold = 10,  # 10-fold CV
  verbose = TRUE,
  early_stopping_rounds = 10  # Stops early if no improvement
)

# Print final CV results
print(cv_results)
```

```{r message=FALSE}
nbastatR_predict <- data2025 %>%
  mutate(point_spread = H_ptsTeam - A_ptsTeam)
```


Figure out how to make the predictions
the column names are different so i need to fix that before i can run that line of code.
```{r}
nbastatR_predict$H_nameTeam <- as.numeric(as.factor(nbastatR_predict$H_nameTeam))
nbastatR_predict$A_nameTeam <- as.numeric(as.factor(nbastatR_predict$A_nameTeam))

nbastatR_predict <- nbastatR_predict %>%
  select(where(is.numeric))

test_features2 <- nbastatR_predict %>% select(-point_spread, -H_ptsTeam, -A_ptsTeam, where(is.numeric)) %>% as.matrix()

test_label2 <- nbastatR_predict$point_spread

dnew <- xgb.DMatrix(data = test_features2, label = test_label2)


dtrain <- xgb.DMatrix(data = train_features, label = train_label)
dtest2 <- xgb.DMatrix(data = test_features2, label = test_label2)

xgb_model <- xgb.train(params = params, 
                       data = dtrain, 
                       nrounds = 100,  
                       watchlist = list(train = dtrain, test = dtest2),
                       verbose = 1)

predictions2 <- predict(xgb_model, dnew) # predictions do not work...fix
mae <- mean(abs(predictions2 - test_label2))
print(paste("MAE:", round(mae, 2)))
```

```{r}
reg_totals_full <- reg_totals_full %>%
  group_by(TEAM_NAME, SEASON_YEAR) %>%
  arrange(GAME_DATE, .by_group = TRUE) %>%
  mutate(GAME_NO_SEASON = row_number()) %>%
  ungroup()

#reg_totals_test <-RS_Totals#reg_totals_test <- reg_totals_full %>% select(TEAM_NAME, GAME_DATE, SEASON_YEAR, GAME_NO_SEASON)

numeric_cols <- setdiff(
  names(select(reg_totals_full, where(is.numeric))),
  c("GAME_ID", "GAME_NO_SEASON")  # add any additional columns you want to exclude
)

### 2) Compute previous-season averages for each team & season
# For each (TEAM_NAME, SEASON_YEAR), calculate the mean of each numeric column.
# Then rename SEASON_YEAR to prev_SEASON_YEAR and prepend "prev_" to each stat.
prev_season_avgs <- reg_totals_full %>%
  group_by(TEAM_NAME, SEASON_YEAR) %>%
  summarise(
    across(all_of(numeric_cols), ~ mean(.x, na.rm = TRUE), .names = "prev_{col}"),
    .groups = "drop"
  ) %>%
  rename(prev_SEASON_YEAR = SEASON_YEAR)

### 3) In current-season data, create a label for the previous season
# For example, if SEASON_YEAR is "2012-13", prev_season_label becomes "2011-12"
rolling_df2 <- NBA_Data2 %>%
  mutate(
    point_spread = H_PTS - A_PTS,
    start_year = as.numeric(substr(SEASON_YEAR, 1, 4)),
    end_year   = as.numeric(substr(SEASON_YEAR, 6, 7)),
    prev_season_label = paste0(start_year - 1, "-", sprintf("%02d", end_year - 1))
  ) %>%
  # Join the previous-season averages (if available) by TEAM_NAME and prev_season_label
  left_join(prev_season_avgs, by = c("TEAM_NAME", "prev_season_label" = "prev_SEASON_YEAR")) %>%
  # Group by team and season, ordering by game date
  group_by(TEAM_NAME, SEASON_YEAR) %>%
  arrange(GAME_DATE, .by_group = TRUE)

### 4) For each numeric column, compute the rolling average column using your logic
# We'll loop over each column name and create a new column "roll_{col}".
for (col in numeric_cols) {
  new_col <- paste0("roll_", col)
  
  rolling_df2 <- rolling_df2 %>%
    mutate(
      !!new_col := {
        # Extract the current column values
        current_vals <- .data[[col]]
        # Compute the cumulative mean (which includes the current game) and lag it by one,
        # so that the current row sees the average of previous games in the season.
        current_cum <- lag(cummean(current_vals), default = NA_real_)
        # The current game's number within the season
        n <- GAME_NO_SEASON
        # Previous season's average for this column (joined in earlier)
        p <- .data[[paste0("prev_", col)]]
        
        # Now compute the rolling value with the 3-phase logic:
        case_when(
          # Game 1: if previous season value exists, use it; otherwise use the current game value.
          n == 1 & !is.na(p) ~ p,
          n == 1 ~ current_vals,
          
          # Games 2-20: if no previous season data, just use current_cum;
          # otherwise, compute weighted blend.
          n < 21 & is.na(p) ~ current_cum,
          n < 21 ~ (1 - 0.05 * (n - 1)) * p + 0.05 * (n - 1) * current_cum,
          
          # Games 21+: use the lagged cumulative average.
          TRUE ~ current_cum
        )
      }
    )
}

### 5) Ungroup and round all new rolling columns to 3 decimals
rolling_df2 <- rolling_df2 %>%
  ungroup() %>%
  mutate(across(starts_with("roll_"), ~ round(.x, 3)))

#prev_season_avgs_test <- prev_season_avgs %>% select(TEAM_NAME, prev_SEASON_YEAR, prev_PTS) %>% filter(TEAM_NAME == "Atlanta Hawks")

#rolling_df2_test <- rolling_df2 %>% select(TEAM_NAME, GAME_DATE, SEASON_YEAR, GAME_NO_SEASON, roll_PTS) %>% filter(TEAM_NAME == "Atlanta Hawks")
```

```{r}
# Modeling Using rolling_df2 (Rolling Averages)

target_col_roll <- "point_spread"  

# Select only rolling averaged features (all columns starting with "roll_")
numeric_features_roll <- rolling_df2 %>%
  select(starts_with("roll_")) %>%
  as.matrix()

# Target variable remains the original Spread column
y_roll <- rolling_df2[[target_col_roll]]
print(y_roll)

if (is.factor(y_roll)) {
  y_roll <- as.numeric(y_roll) - 1  
}

# Standardize the rolling features
preproc_roll <- preProcess(numeric_features_roll, method = c("center", "scale"))
numeric_features_roll <- predict(preproc_roll, numeric_features_roll)

set.seed(123)
folds_roll <- createFolds(y_roll, k = 10, list = TRUE, returnTrain = TRUE)

# Create a new DMatrix for rolling data
dtrain_roll <- xgb.DMatrix(data = numeric_features_roll, label = y_roll)

# Define parameters for the rolling model
params_roll <- list(
  objective = "reg:squarederror",  # Regression task
  eval_metric = "mae",  # Mean Absolute Error (MAE)
  max_depth = 6,  
  eta = 0.05,  
  subsample = 0.8, 
  colsample_bytree = 0.8,
  nrounds = 200,
  early_stopping_rounds = 10
)

# Perform 10-fold cross-validation on the rolling data
cv_results_roll <- xgb.cv(
  params = params_roll,
  data = dtrain_roll,
  nrounds = 200,
  nfold = 10,                     # 10-Fold Cross-Validation
  early_stopping_rounds = 10,
  verbose = TRUE,
  prediction = TRUE              # Capture fold-wise predictions
)

# Extract evaluation results
fold_mae_roll <- cv_results_roll$evaluation_log$test_mae_mean  # Mean MAE for each round
best_round_roll <- cv_results_roll$best_iteration              # Best iteration based on early stopping
best_mae_roll <- fold_mae_roll[best_round_roll]                 # Best MAE at the chosen iteration

# Compute Mean Absolute Deviation (MAD) for each fold
mad_values_roll <- abs(cv_results_roll$pred - y_roll)  
cat("MAD values for each fold (rolling data):\n")
print(mad_values_roll)

# Compute and print average MAD
avg_mad_roll <- mean(mad_values_roll)
cat("Average MAD across all folds (rolling data):", round(avg_mad_roll, 4), "\n")

# Train the final model on the full rolling dataset using best iteration from CV
xgb_model_roll_total <- xgb.train(
  params = params_roll,
  data = dtrain_roll,
  nrounds = best_round_roll  # Use the best number of rounds from CV
)

# Feature Importance for rolling data model
importance_roll <- xgb.importance(feature_names = colnames(numeric_features_roll), model = xgb_model_roll_total)
xgb.plot.importance(importance_roll)
```
